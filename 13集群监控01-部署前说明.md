[TOC]

**前言：**为什么写这个文章，因为在跟着各种文档装完一堆监控的东西后，觉得有必要理一理这些组件之间的关系

装完一堆监控后，你可能听过这些词：`heapster`,`metrics-server`,`prometheus`,`prometheus-operator`,`prometheus-server`,`alertmanager`,`grafana`,`kube-state-metrics`,`node-exporter`,`prometheus-adapter`等等。本文将以我自己的所知，记录下这些东西的区别。

# 1. `heapster`

这玩意是原来的核心指标采集(提供)工具，效果跟`metrics-server`差不多，都是提供node和Pod的CPU和内存使用情况。安装后，你的`dashboard`里才会显示CPU，内存使用率这些东西。现已经废弃，改用`metrics-server`。

# 2. metrics-server

这玩意就是用来展示核心指标的，目前仅限于node和Pod的CPU和内存使用情况。同样的，`dashboard-v2`从这个组件上获取node和Pod的CPU和内存数据。装了后你就能使用`kubectl top node`和`kubectl top pod`了，`HPA`的依赖。不是非装不可。装了``prometheus`全套后，可以不需要这东西。

```bash
# kubectl top node
NAME        CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   
k8s-node1   281m         16%    1328Mi          38%       
k8s-node2   99m          5%     1460Mi          46%       
lb01        55m          3%     434Mi           12%       
lb02        72m          4%     509Mi           14%       
# kubectl top pod
NAME                              CPU(cores)   MEMORY(bytes)   
coredns-6d77f857f7-5j5wv          5m           8Mi             
coredns-6d77f857f7-7wtt4          12m          9Mi             
coredns-6d77f857f7-wbkm5          6m           8Mi             
kube-flannel-ds-amd64-4fpct       2m           11Mi            
kube-flannel-ds-amd64-574mv       2m           10Mi            
kube-flannel-ds-amd64-bm6t2       3m           8Mi             
kube-flannel-ds-amd64-q5x75       10m          10Mi            
metrics-server-7cdb558858-lsjgl   3m           29Mi            
```

项目地址是： https://github.com/kubernetes-sigs/metrics-server 

# 3. `prometheus`

这是k8s官方推荐的监控方案。基于Go编写，可独立部署，是监控的服务端，从各种exporter里pull数据并存储为时序数据。后面的一堆东西都围绕着这个转，这东西在我看来就是个数据采集器，只不过他保存的是时序数据，这玩意讲的高大上似的，搞的我以为是什么东西。无外乎就是把时间，监控项名，数据全放一块保存了。只要你提供给它的数据格式如下，它就能收

```bash
# HELP node_cpu Seconds the cpus spent in each mode.
# TYPE node_cpu counter
node_cpu{cpu="cpu0",mode="idle"} 362812.7890625
# HELP node_load1 1m load average.
# TYPE node_load1 gauge
node_load1 3.0703125
```

官网是： https://prometheus.io/ 

项目地址是： https://github.com/prometheus 

# 4. `prometheus-operator`

`prometheus-operator`是个全家桶，它把后面那些东西全整合在一块了，你可以直接apply这个目录就能把这些全给简易的安装了。现在改名叫`kube-prometheus`。

为什么需要它？ 因为是`prometheus`主动去拉取的,所以在`k8s`里pod因为调度的原因导致pod的`ip`会发生变化,人工不可能去维持,自动发现有基于`DNS`的,但是新增还是有点麻烦 。 Prometheus-operator的本职就是一组用户自定义的`CRD`资源以及Controller的实现，Prometheus Operator这个controller有`RBAC`权限下去负责监听这些自定义资源的变化，并且根据这些资源的定义自动化的完成如Prometheus Server自身以及配置的自动化管理工作 

项目地址是： https://github.com/coreos/kube-prometheus 

# 5. `prometheus-server`

`prometheus-server`其实就是`prometheus`，类似于`zabbix_server`

# 6. `alertmanager`

`alertmanager`就是负责处理`prometheus`交给它的报警规则的。由它决定要不要报警，发送给谁。这也是`prometheus`自己家的产品。

其配置格式如下：

```yaml
global:
  [ resolve_timeout: <duration> | default = 5m ]
  [ smtp_from: <tmpl_string> ] 
  [ smtp_smarthost: <string> ] 
  [ smtp_hello: <string> | default = "localhost" ]
  [ smtp_auth_username: <string> ]
  [ smtp_auth_password: <secret> ]
  [ smtp_auth_identity: <string> ]
  [ smtp_auth_secret: <secret> ]
  [ smtp_require_tls: <bool> | default = true ]
  [ slack_api_url: <secret> ]
  [ victorops_api_key: <secret> ]
  [ victorops_api_url: <string> | default = "https://alert.victorops.com/integrations/generic/20131114/alert/" ]
  [ pagerduty_url: <string> | default = "https://events.pagerduty.com/v2/enqueue" ]
  [ opsgenie_api_key: <secret> ]
  [ opsgenie_api_url: <string> | default = "https://api.opsgenie.com/" ]
  [ hipchat_api_url: <string> | default = "https://api.hipchat.com/" ]
  [ hipchat_auth_token: <secret> ]
  [ wechat_api_url: <string> | default = "https://qyapi.weixin.qq.com/cgi-bin/" ]
  [ wechat_api_secret: <secret> ]
  [ wechat_api_corp_id: <string> ]
  [ http_config: <http_config> ]

templates:
  [ - <filepath> ... ]

route: <route>

receivers:
  - <receiver> ...

inhibit_rules:
  [ - <inhibit_rule> ... ]
```

`Alertmanager`主要负责对Prometheus产生的告警进行统一处理，因此在`Alertmanager`配置中一般会包含以下几个主要部分：

- 全局配置（global）：用于定义一些全局的公共参数，如全局的SMTP配置，Slack配置等内容；
- 模板（templates）：用于定义告警通知时的模板，如HTML模板，邮件模板等；
- 告警路由（route）：根据标签匹配，确定当前告警应该如何处理；
- 接收人（receivers）：接收人是一个抽象的概念，它可以是一个邮箱也可以是微信，Slack或者`Webhook`等，接收人一般配合告警路由使用；
- 抑制规则（inhibit_rules）：合理设置抑制规则可以减少垃圾告警的产生

# 7. `grafana`

这个不陌生了吧，在`zabbix`就用过它了。就是个图形展示工具。跟监控并没有什么必然联系，只是用它做的图形比较漂亮。

# 8. `kube-state-metrics`

 Prometheus可以采集其它各种指标，但是`prometheus`采集到的metrics并不能直接给`k8s`用，因为两者数据格式不兼容，因此还需要另外一个组件(`kube-state-metrics`)，将`prometheus的metrics`数据格式转换成`k8s` `API`接口能识别的格式，转换以后，因为是自定义`API`，所以还需要用``Kubernetes aggregator`在主`API`服务器中注册(这个由`prometheus-adapter`完成)，以便直接通过`/apis/`来访问。 

# 9. node-exporter

这个组件是用来采取node级别的信息。将node的信息转成`prometheus`能读懂的格式，并提供一个接口，供`prometheus`从它这里pull数据。类似于`zabbix_agent`的作用。

# 10. `prometheus-adapter`

聚合`apiserver`，即提供了一个`apiserver【custom-metrics-api】`，自定义`APIServer`通常都要通过`Kubernetes aggregator`聚合到apiserver。就是可以通过kubectl api-versions里查到` custom.metrics.k8s.io `意味着可以通过kubectl获取对应数据。

 kubernetes的监控指标分为两种： 

- Core metrics(核心指标)：从 Kubelet、cAdvisor 等获取度量数据，再由metrics-server提供给 Dashboard、HPA 控制器等使用。
- Custom Metrics(自定义指标)：由Prometheus Adapter提供API custom.metrics.k8s.io，由此可支持任意Prometheus采集到的指标。

 核心指标只包含node和pod的cpu、内存等，一般来说，核心指标作HPA已经足够，但如果想根据自定义指标:如请求qps/5xx错误数来实现HPA，就需要使用自定义指标了，目前Kubernetes中自定义指标一般由Prometheus来提供，再利用k8s-prometheus-adpater聚合到apiserver，实现和核心指标（metric-server)同样的效果。 

 其实prometheus-adapter既包含自定义指标，又包含核心指标，即如果安装了prometheus，且指标都采集完整，prometheus-adapter可以替代metrics server。 

# 11. CAdvisor

 用户可以通过Docker的stats命令获取到当前主机上运行容器的统计信息，可以查看容器的CPU利用率、内存使用量、网络IO总量以及磁盘IO总量等信息。  除了使用命令以外，用户还可以通过Docker提供的HTTP API查看容器详细的监控统计信息。 

```bash
docker stats
```



CAdvisor是Google开源的一款用于展示和分析容器运行状态的可视化工具。通过在主机上运行CAdvisor用户可以轻松的获取到当前主机上容器的运行统计信息，并以图表的形式向用户展示。

在本地运行CAdvisor也非常简单，直接运行一下命令即可：

```bash
docker run \
  --volume=/:/rootfs:ro \
  --volume=/var/run:/var/run:rw \
  --volume=/sys:/sys:ro \
  --volume=/var/lib/docker/:/var/lib/docker:ro \
  --publish=8080:8080 \
  --detach=true \
  --name=cadvisor \
  google/cadvisor:latest
```

CAdvisor是一个简单易用的工具，相比于使用Docker命令行工具，用户不用再登录到服务器中即可以可视化图表的形式查看主机上所有容器的运行状态。

而在多主机的情况下，在所有节点上运行一个CAdvisor再通过各自的UI查看监控信息显然不太方便，同时CAdvisor默认只保存2分钟的监控数据。好消息是CAdvisor已经内置了对Prometheus的支持。访问http://localhost:8080/metrics即可获取到标准的Prometheus监控样本输出:

下面表格中列举了一些CAdvisor中获取到的典型监控指标：

| 指标名称                               | 类型    | 含义                                         |
| -------------------------------------- | ------- | -------------------------------------------- |
| container_cpu_load_average_10s         | gauge   | 过去10秒容器CPU的平均负载                    |
| container_cpu_usage_seconds_total      | counter | 容器在每个CPU内核上的累积占用时间 (单位：秒) |
| container_cpu_system_seconds_total     | counter | System CPU累积占用时间（单位：秒）           |
| container_cpu_user_seconds_total       | counter | User CPU累积占用时间（单位：秒）             |
| container_fs_usage_bytes               | gauge   | 容器中文件系统的使用量(单位：字节)           |
| container_fs_limit_bytes               | gauge   | 容器可以使用的文件系统总量(单位：字节)       |
| container_fs_reads_bytes_total         | counter | 容器累积读取数据的总量(单位：字节)           |
| container_fs_writes_bytes_total        | counter | 容器累积写入数据的总量(单位：字节)           |
| container_memory_max_usage_bytes       | gauge   | 容器的最大内存使用量（单位：字节）           |
| container_memory_usage_bytes           | gauge   | 容器当前的内存使用量（单位：字节             |
| container_spec_memory_limit_bytes      | gauge   | 容器的内存使用量限制                         |
| machine_memory_bytes                   | gauge   | 当前主机的内存总量                           |
| container_network_receive_bytes_total  | counter | 容器网络累积接收数据总量（单位：字节）       |
| container_network_transmit_bytes_total | counter | 容器网络累积传输数据总量（单位：字节）       |

这个已经内置到kubelet中了，所以无需安装。

# 12. 监控维度

| 目标                                                         | 发现方式  | 监控方法 | 数据源            |
| ------------------------------------------------------------ | --------- | -------- | ----------------- |
| 从集群各节点kubelet组件中获取节点kubelet的基本运行状态的监控指标 | node      | 白盒监控 | kubelet           |
| 从集群各节点kubelet内置的cAdvisor中获取，节点中运行的容器的监控指标 | node      | 白盒监控 | kubelet           |
| 从部署到各个节点的Node Exporter中采集主机资源相关的运行资源  | node      | 白盒监控 | node exporter     |
| 对于内置了Promthues支持的应用，需要从Pod实例中采集其自定义监控指标 | pod       | 白盒监控 | custom pod        |
| 获取API Server组件的访问地址，并从中获取Kubernetes集群相关的运行监控指标 | endpoints | 白盒监控 | api server        |
| 获取集群中Service的访问地址，并通过Blackbox Exporter获取网络探测指标 | service   | 黑盒监控 | blackbox exporter |
| 获取集群中Ingress的访问信息，并通过Blackbox Exporter获取网络探测指标 | ingress   | 黑盒监控 | blackbox exporter |
|                                                              |           |          |                   |



# kube-prometheus说明

项目地址： https://github.com/coreos/kube-prometheus 

先把项目拉取下来：

```bash
git clone  https://github.com/coreos/kube-prometheus
```

目录结构

```bash
# tree
.
├── build.sh
├── code-of-conduct.md
├── DCO
├── docs
│   ├── developing-prometheus-rules-and-grafana-dashboards.md
│   ├── EKS-cni-support.md
│   ├── exposing-prometheus-alertmanager-grafana-ingress.md
│   ├── GKE-cadvisor-support.md
│   ├── kube-prometheus-on-kubeadm.md
│   ├── monitoring-external-etcd.md
│   └── monitoring-other-namespaces.md
├── example.jsonnet
├── examples
│   ├── additional-namespaces.jsonnet
│   ├── additional-namespaces-servicemonitor.jsonnet
│   ├── alertmanager-config-external.jsonnet
│   ├── alertmanager-config.jsonnet
│   ├── alertmanager-config.yaml
│   ├── auth
│   ├── basic-auth
│   │   ├── secrets.yaml
│   │   └── service-monitor.yaml
│   ├── eks-cni-example.jsonnet
│   ├── etcd-client-ca.crt
│   ├── etcd-client.crt
│   ├── etcd-client.key
│   ├── etcd.jsonnet
│   ├── etcd-skip-verify.jsonnet
│   ├── example-app
│   │   ├── example-app.yaml
│   │   ├── prometheus-frontend-alertmanager-discovery-role-binding.yaml
│   │   ├── prometheus-frontend-alertmanager-discovery-role.yaml
│   │   ├── prometheus-frontend-role-binding.yaml
│   │   ├── prometheus-frontend-role.yaml
│   │   ├── prometheus-frontend-service-account.yaml
│   │   ├── prometheus-frontend-svc.yaml
│   │   ├── prometheus-frontend.yaml
│   │   └── servicemonitor-frontend.yaml
│   ├── example-grafana-dashboard.json
│   ├── existingrule.json
│   ├── existingrule.yaml
│   ├── grafana-additional-jsonnet-dashboard-example.jsonnet
│   ├── grafana-additional-rendered-dashboard-example-2.jsonnet
│   ├── grafana-additional-rendered-dashboard-example.jsonnet
│   ├── ingress.jsonnet
│   ├── internal-registry.jsonnet
│   ├── jsonnet-build-snippet
│   │   └── build-snippet.jsonnet
│   ├── jsonnet-snippets
│   │   ├── bootkube.jsonnet
│   │   ├── kops-coredns.jsonnet
│   │   ├── kops.jsonnet
│   │   ├── kubeadm.jsonnet
│   │   ├── kube-aws.jsonnet
│   │   ├── kubespray.jsonnet
│   │   └── node-ports.jsonnet
│   ├── ksonnet-example.jsonnet
│   ├── kustomize.jsonnet
│   ├── minikube.jsonnet
│   ├── prometheus-additional-alert-rule-example.jsonnet
│   ├── prometheus-additional-recording-rule-example.jsonnet
│   ├── prometheus-additional-rendered-rule-example.jsonnet
│   ├── prometheus-name-override.jsonnet
│   ├── prometheus-pvc.jsonnet
│   └── tolerations.libsonnet
├── experimental
│   ├── custom-metrics-api
│   │   ├── custom-metrics-apiserver-resource-reader-cluster-role-binding.yaml
│   │   ├── custom-metrics-apiservice.yaml
│   │   ├── custom-metrics-cluster-role.yaml
│   │   ├── custom-metrics-configmap.yaml
│   │   ├── deploy.sh
│   │   ├── hpa-custom-metrics-cluster-role-binding.yaml
│   │   ├── README.md
│   │   ├── sample-app.yaml
│   │   └── teardown.sh
│   └── metrics-server
│       ├── auth-delegator.yaml
│       ├── auth-reader.yaml
│       ├── metrics-apiservice.yaml
│       ├── metrics-server-cluster-role-binding.yaml
│       ├── metrics-server-cluster-role.yaml
│       ├── metrics-server-deployment.yaml
│       ├── metrics-server-service-account.yaml
│       └── metrics-server-service.yaml
├── go.mod
├── go.sum
├── hack
│   ├── example-service-monitoring
│   │   ├── deploy
│   │   └── teardown
│   └── jsonnet-docker-image
├── jsonnet
│   └── kube-prometheus
│       ├── alertmanager
│       │   └── alertmanager.libsonnet
│       ├── alerts
│       │   ├── alertmanager.libsonnet
│       │   ├── alerts.libsonnet
│       │   ├── general.libsonnet
│       │   ├── node.libsonnet
│       │   ├── prometheus-operator.libsonnet
│       │   └── tests.yaml
│       ├── jsonnetfile.json
│       ├── ksm-autoscaler
│       │   └── ksm-autoscaler.libsonnet
│       ├── kube-prometheus-anti-affinity.libsonnet
│       ├── kube-prometheus-bootkube.libsonnet
│       ├── kube-prometheus-config-mixins.libsonnet
│       ├── kube-prometheus-eks.libsonnet
│       ├── kube-prometheus-insecure-kubelet.libsonnet
│       ├── kube-prometheus-kops-coredns.libsonnet
│       ├── kube-prometheus-kops.libsonnet
│       ├── kube-prometheus-ksonnet.libsonnet
│       ├── kube-prometheus-kubeadm.libsonnet
│       ├── kube-prometheus-kube-aws.libsonnet
│       ├── kube-prometheus-kubespray.libsonnet
│       ├── kube-prometheus.libsonnet
│       ├── kube-prometheus-managed-cluster.libsonnet
│       ├── kube-prometheus-node-ports.libsonnet
│       ├── kube-prometheus-static-etcd.libsonnet
│       ├── kube-prometheus-strip-limits.libsonnet
│       ├── kube-prometheus-thanos-sidecar.libsonnet
│       ├── kube-state-metrics
│       │   └── kube-state-metrics.libsonnet
│       ├── lib
│       │   ├── image.libsonnet
│       │   └── lib.libsonnet
│       ├── node-exporter
│       │   └── node-exporter.libsonnet
│       ├── prometheus
│       │   └── prometheus.libsonnet
│       ├── prometheus-adapter
│       │   └── prometheus-adapter.libsonnet
│       └── rules
│           ├── node-rules.libsonnet
│           └── rules.libsonnet
├── jsonnetfile.json
├── jsonnetfile.lock.json
├── kustomization.yaml
├── LICENSE
├── Makefile
├── manifests
│   ├── alertmanager-alertmanager.yaml
│   ├── alertmanager-secret.yaml
│   ├── alertmanager-serviceAccount.yaml
│   ├── alertmanager-serviceMonitor.yaml
│   ├── alertmanager-service.yaml
│   ├── grafana-dashboardDatasources.yaml
│   ├── grafana-dashboardDefinitions.yaml
│   ├── grafana-dashboardSources.yaml
│   ├── grafana-deployment.yaml
│   ├── grafana-serviceAccount.yaml
│   ├── grafana-serviceMonitor.yaml
│   ├── grafana-service.yaml
│   ├── kube-state-metrics-clusterRoleBinding.yaml
│   ├── kube-state-metrics-clusterRole.yaml
│   ├── kube-state-metrics-deployment.yaml
│   ├── kube-state-metrics-roleBinding.yaml
│   ├── kube-state-metrics-role.yaml
│   ├── kube-state-metrics-serviceAccount.yaml
│   ├── kube-state-metrics-serviceMonitor.yaml
│   ├── kube-state-metrics-service.yaml
│   ├── node-exporter-clusterRoleBinding.yaml
│   ├── node-exporter-clusterRole.yaml
│   ├── node-exporter-daemonset.yaml
│   ├── node-exporter-serviceAccount.yaml
│   ├── node-exporter-serviceMonitor.yaml
│   ├── node-exporter-service.yaml
│   ├── prometheus-adapter-apiService.yaml
│   ├── prometheus-adapter-clusterRoleAggregatedMetricsReader.yaml
│   ├── prometheus-adapter-clusterRoleBindingDelegator.yaml
│   ├── prometheus-adapter-clusterRoleBinding.yaml
│   ├── prometheus-adapter-clusterRoleServerResources.yaml
│   ├── prometheus-adapter-clusterRole.yaml
│   ├── prometheus-adapter-configMap.yaml
│   ├── prometheus-adapter-deployment.yaml
│   ├── prometheus-adapter-roleBindingAuthReader.yaml
│   ├── prometheus-adapter-serviceAccount.yaml
│   ├── prometheus-adapter-service.yaml
│   ├── prometheus-clusterRoleBinding.yaml
│   ├── prometheus-clusterRole.yaml
│   ├── prometheus-operator-serviceMonitor.yaml
│   ├── prometheus-prometheus.yaml
│   ├── prometheus-roleBindingConfig.yaml
│   ├── prometheus-roleBindingSpecificNamespaces.yaml
│   ├── prometheus-roleConfig.yaml
│   ├── prometheus-roleSpecificNamespaces.yaml
│   ├── prometheus-rules.yaml
│   ├── prometheus-serviceAccount.yaml
│   ├── prometheus-serviceMonitorApiserver.yaml
│   ├── prometheus-serviceMonitorCoreDNS.yaml
│   ├── prometheus-serviceMonitorKubeControllerManager.yaml
│   ├── prometheus-serviceMonitorKubelet.yaml
│   ├── prometheus-serviceMonitorKubeScheduler.yaml
│   ├── prometheus-serviceMonitor.yaml
│   ├── prometheus-service.yaml
│   └── setup
│       ├── 0namespace-namespace.yaml
│       ├── prometheus-operator-0alertmanagerCustomResourceDefinition.yaml
│       ├── prometheus-operator-0podmonitorCustomResourceDefinition.yaml
│       ├── prometheus-operator-0prometheusCustomResourceDefinition.yaml
│       ├── prometheus-operator-0prometheusruleCustomResourceDefinition.yaml
│       ├── prometheus-operator-0servicemonitorCustomResourceDefinition.yaml
│       ├── prometheus-operator-clusterRoleBinding.yaml
│       ├── prometheus-operator-clusterRole.yaml
│       ├── prometheus-operator-deployment.yaml
│       ├── prometheus-operator-serviceAccount.yaml
│       └── prometheus-operator-service.yaml
├── NOTICE
├── OWNERS
├── README.md
├── scripts
│   ├── minikube-start-kvm.sh
│   ├── minikube-start.sh
│   └── monitoring-deploy.sh
├── sync-to-internal-registry.jsonnet
├── tests
│   └── e2e
│       ├── main_test.go
│       ├── prometheus_client.go
│       └── travis-e2e.sh
└── test.sh

27 directories, 196 files
```

主要文件和目录说明：

```bash
manifests: 放的都是监控组件的yaml文件
mainfests/setup：这个是要先执行，作用是创建namespace和CRDs
scripts/monitoring-deploy.sh：一键部署kube-prometheus的脚本
```

`scripts/monitoring-deploy.sh`脚本内容：

```bash
#!/bin/bash
  
# create namespace and CRDs
kubectl create -f manifests/setup

# wait for CRD creation to complete
until kubectl get servicemonitors --all-namespaces ; do date; sleep 1; echo ""; done

# create monitoring components
kubectl create -f manifests/
```

`manifests/setup`下各文件说明

| 文件名                                                       | 作用                                                  | 备注                                     |
| ------------------------------------------------------------ | ----------------------------------------------------- | ---------------------------------------- |
| 0namespace-namespace.yaml                                    | 创建monitoring这个namespace                           | 最先执行，后面的监控组件全放在这个空间里 |
| prometheus-operator-0alertmanagerCustomResourceDefinition.yaml | 创建alertmanagers.monitoring.coreos.com这个自定义资源 |                                          |
| prometheus-operator-0podmonitorCustomResourceDefinition.yaml | 创建podmonitors.monitoring.coreos.com                 |                                          |
| prometheus-operator-0prometheusCustomResourceDefinition.yaml | prometheuses.monitoring.coreos.com                    |                                          |
| prometheus-operator-0prometheusruleCustomResourceDefinition.yaml | prometheusrules.monitoring.coreos.com                 | PrometheusRule                           |
| prometheus-operator-0servicemonitorCustomResourceDefinition.yaml | servicemonitors.monitoring.coreos.com                 | 这五个文件第2执行                        |
| prometheus-operator-clusterRoleBinding.yaml                  |                                                       | 后面这几个才是部署operator的，第3执行    |
| prometheus-operator-clusterRole.yaml                         |                                                       |                                          |
| prometheus-operator-deployment.yaml                          |                                                       |                                          |
| prometheus-operator-serviceAccount.yaml                      |                                                       |                                          |
| prometheus-operator-service.yaml                             |                                                       |                                          |

